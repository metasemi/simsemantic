Project for exploring the semantic trajectories of text streams, the motivating cases being GPT prompt/completion/prompt/completion sequences, as described in @janus's [Simulators](https://www.alignmentforum.org/posts/vJFdjigzmcXMhNTsx/simulators) post, and LLM-generated branching "multiverses" of such streams, as described in [Language models are multiverse generators](https://generative.ink/posts/language-models-are-multiverse-generators/). For this purpose, streams are understood as mappings from discrete 'time' to text prefixes ('states'). For example, in the case of the GPT prompt "Mary had" and completion " a little downtime.", the stream states could be schematized as [ "Mary", "Mary had", "Mary had a", "Mary had a little", "Mary had a little downtime", "Mary had a little downtime." ].

The *semantic trajectory* of a text stream is defined to be a mapping from discrete time to semantic representations, where each semantic representation is the context-free semantic representation of a single state of the given text stream. Currently, the semantic representations supported are the [OpenAI semantic embeddings](https://beta.openai.com/docs/guides/embeddings/what-are-embeddings), and semantic trajectories are represented as streams of deltas between successive per-token embedding vectors.
